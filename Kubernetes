What is Kubernetes ?
Kubernetes is an open-source container orchestration platform developed by Google and now maintained by the Cloud Native Computing Foundation (CNCF). 
It is designed to automate the deployment, scaling, and management of containerized applications. Containers are lightweight, 
portable units of software that include everything needed to run an application, such as code, libraries, and dependencies.

What is POD ?
In Kubernetes (K8s), a Pod is the smallest and most basic deployable unit. It represents a single instance of a running process in your cluster and typically contains one or more containers (often Docker containers).
Containers in a Pod share storage volumes, which allows them to access the same data.
They also share the same network namespace, meaning they can communicate with each other using localhost.
Pods are designed to be ephemeral. When a Pod is deleted, it doesnâ€™t come back; instead, a new Pod is created with a new IP address.

What is Deployment ?
In Kubernetes, a Deployment is a higher-level abstraction, make it easier to scale, update, and manage your application by automating the creation and management of Pods.
A Deployment can manage multiple replicas (instances) of Pods, allowing you to scale up or down easily by adjusting the replicas field in the configuration.
Kubernetes will ensure that the specified number of replicas are always running.
If a Pod fails or goes unhealthy, Kubernetes automatically replaces it to maintain the desired number of replicas.

what is service ?
In Kubernetes, a Service is an abstraction that defines a logical set of Pods and enables network access to them. Services help expose an application running on multiple Pods as a single, 
unified network endpoint, allowing external or internal access based on configuration.

what is ingress ?
In Kubernetes, an Ingress is an API object that manages external access to services within the cluster, typically over HTTP and HTTPS. Ingress can route traffic from the outside world to the right services based on routing rules. 
It provides a way to define rules to expose services externally, supporting advanced features such as load balancing, SSL/TLS termination, and name-based virtual hosting.
Components of Ingress
Ingress Controller:
To use Ingress, a cluster must have an Ingress Controller running. The Ingress Controller watches for Ingress resources and configures the network layer accordingly. Examples include NGINX, HAProxy, and Traefik.
Ingress Rules:
Each Ingress resource contains rules defining how traffic should be routed based on hostnames and paths.


what is the difference between docker and k8s ?
Docker is a container platform, where as kubernetes is a container orchestration environment that offers 
 capabilities like auto scalling, auto healing, clustering and enterprise level support like load balancing.

what is the difference between docker swarm and k8s ? 
k8s is better suited for large organisations as it offers more scalability, networking capabilities like
like policies and huge third party ecosystem support.
docker swarm is docker based solution, it is easy to use and it is well suited for small scale application because th support for
scalling and auto healing are very limited in doceker swarm

what is the difference between docker container and k8s pods?
A Docker container is a lightweight, standalone package that includes everything needed to run a piece of software, such as code, libraries, and system tools. 
In contrast, a Kubernetes pod is a higher-level abstraction that can encapsulate one or more containers, allowing them to share resources like network and storage. 
Essentially, while containers are the individual units of deployment, pods serve as the management layer for those containers within Kubernetes.
we can run multiple containers in pods.

what is namespace in k8s?
A Kubernetes namespace is a mechanism for isolating groups of resources within a single Kubernetes cluster, allowing for better organization and management.
Namespaces enable multiple teams or projects to share the same cluster without interfering with each other's resources, as each namespace has its own scope for resource names, which must be unique only within that namespace. 
Kubernetes automatically creates several default namespaces, including default, kube-system, kube-public, and kube-node-lease, and administrators can create custom namespaces as needed to enhance security and resource allocation

What is the role of kube proxy?
Kube proxy works by maintaining a set of network rules on each node in the cluster, which are updated dynamically as services are added or removed. when a client sends a requests to a service, 
the request is intercepted by kube proxy on the node where it was received. kube proxy then looks up the destination endpoint for the service and routes the request accordingly.
Kube proxy is an essential component of a k8s cluster, as it ensures that servix=ces can communicate with each other.

Q: What is a Kubernetes cluster?
A Kubernetes cluster is a logical grouping of EC2 compute instances that run your containers. A cluster consists of the control plane (the instances that control how, when, and where your containers run), 
and the data plane (the instances where your containers run). You must define a cluster before you can run containers or services with Kubernetes.

Q: What is a Kubernetes node?
A Kubernetes node is a single compute instance (virtual machine) that is part of a Kubernetes cluster. There are two types of instances: masters and workers. Masters host the Kubernetes API server and control how, when, 
and where your containers run. Workers are the compute instances where your containers actually run and process data.

Q: What is a Kubernetes pod?
A Kubernetes pod is the way that Kubernetes runs containers on a compute instance and includes containers and specifications for how they should run, networking, and storage. A pod can be a single container or multiple containers that always run together. 
If you usually run single containers, you can think of a pod as a running container.

Q: What is etcd?
A etcd is a distributed key value store that lets you store and share data across a distributed cluster of machines. Kubernetes uses etcd to store data about your cluster and share it across the Kubernetes control plane.


Disadvantages of Docker
1. Docker is a single host.
  ex: i have a host on top of it i install docker and i run 100 containers on it, among all of it 1 st container takes lots of memory,
      compared to last container, so that the kernel will kill last container.one of the container will die because of other containers, this is because of single host
2. Not having a Auto healing feature
3. Docker does not support Enterprise level support

These Disadvantages will overcome by Kubernetes

to use minikube on ec2 instance
- install kubectl --> documentation
change permission to the kubectl file   - sudo chmod +x kubectl
                                          sudo mv kubectl /usr/loacl/bin
check kubectl version - kubectl version
- install minikube --> documentation
- install docker for minikube
then use command - minikube start
to start the minikube

what is minikube ?
it is a command line tool that allows you to create kubernetes cluster

to know the details of nodes in cluster command
kubectl get nodes
our kubectl is connected to the kubernates cluster then it gives the nodes

now create a pod
pod is a yaml file that contains the specifications of our container like port mapping, volumes, type of network

vi pod.yml ----> write yaml file for that

for creation of pod command
kubectl create -f pod.yml   ---> this will create our pod 
to see the pods commad
kubectl get pods ---> shows the available pods
kubectl get pods -o wide  ---> it shows all details including ip

if you want to enter into the cluster command
minikube ssh  ---> now you are in minikube cluster if you enter "docker images" command there you can see kuberneter master components like scheduler, api server, etcd etc

to know more about kubenertes commands use "kubectl cheetsheet"

to delete the pod command
kubectl delete pod <podfile.yml name>

if you want to debug the pod or to know the status of the pod command
"kubectl describe pod <name>" --->  this will give all the information of everything inside the pod

difference between pod and container and deployment ?
container :- its a package that contains all necessary dependencies require foan appication, we create a container using any cntainerized platform like docker
              if we run that container we use command called "docker run -d -p 80:80 -it --network=xxx <name>"
pod :- pod is a smallest and simplest unit that you can deploy, it contains one or multiple containers, all containers in the pod can share same volume and same network.

deployment :- why we came from docker to kubernetes because the lack of auto scalling and auto healing eatres in docker. in deployment we can see these features. 
                it is a yaml file (deployment.yml); in this yaml file we spicify how many replicas(pods) we want, so that our kubernetes cluster will maintain that number of pods in cluster
                if someone delete any of the pod by mistake, it will create new pod based on our specification to match the replica count it is called auto healing.

to create deploy, first we create deployment.yaml
command to create deploy "kubectl apply -f <deployment.yaml>
if we create deploy, it creates pod and replicaset
command to view -- kubectl get deploy  ---> to list the deploys
                    kubectl get pods  ---> to list the pods
                    kubectl get rs   ---> for replica sets

Kubernetes Service

In deployment we have a feature like auto healing, like for an example if i have 3 pods (172.17.8.1, 172.17.8.2, 172.17.8.3) they have they individual IPs
whenever if any pod has down, the auto healing will automatically create a new pod but the new pod has new ip i.e., 172.17.8.5
this is one of the drawback for accessing the pod everytime its changes the ip

When a pod replica dies, a new pod replaces with new ip adress as a feature of auto healing

Service  created on top of development and it acts as load balancer. Instead of accessing the ips of every single pod, service is used instead.
Service using the kube-proxy will forward the request to underlying pod based on label and selectors, load balancing them out at the same time.
Service keep tracks of pods based on labels and selectors instead of ip adress, since ip adress are bound to change.
Service also expose your application to the external world, for end user to use the application.
In kubernetes service we have loadbalancing instead of ip we access the pods with dns name, so if any pod is created with new ip we can access it with the DNS name
By using kubernetes service we can expose our appication, it allows our application to outside the kubernetes cluster.
we can create the k8s service in 3 types:
1. cluster IP. ---> we can access the application only who has the access to the kuberntes node or access inside the kubernetes 
2. Nodeport.  ---> we can access the application withn the network or within the organisation those who are in VPC
3. Loadbalancing. ---< we can access it globally.

to execute the file we have to use the command
"kubectl apply -f <service fle name.yml>"
to view that use command "kubectl get svc"

to see all pods, deployments, replicas use commands
"kubectl get all"

ingress
if i create a service with network type called loadbalcner, my cloud provider give a create a loadbalncer and dns name.
For ex: if i have multiple serivices and i want to run all services so it create so many loadbalancers to access those services, our cloud provider charges a lot for this.
to overcome this INGRESS comes into picture.

In Kubernetes, ingress is an PI object that provides external access to services witin a cluser.
It acts as a layer 7(application layer) load balancer allowing external traffic to be routed to diferent services based on HTTP/HTTPS routes and rules.
we have two components in ingress they are:
           1. Ingress Controller
           2. Ingress resources
Ingress controller is the main component of ingress, the incoming traffic will first hit the ingress controoler, then it checks the ingress resource
Ingress resource, in this we define the rules for the services what kind of traffic will flow in  the cluster,  



RBAC (Role base access control)
Two primary responsibility of RBAC user management as well as managing the access of the services that are runnimg on the cluster.

in an organization we have admin cluster what if some one or some action, delete etcd or kube system its a huge loss for the team to overcoe that,
depending on the ROLE of the person we would define ACCESS and CONTROL.

in an service account we launch a malicious pod that will going to deleting some centen related to api server or config maps.
in that scenario we define what access does this pod need in the k8s cluster, should this pod access to config maps, should access for secrets we define the rules for it 
for managing the RBAC we need
1. service account / users
2. Roles / Cluster Role
3. Role binding / Cluster role binding


Config maps and secret
what is config map ?
config map solving the problem of storing the information, that can be used for our applicayion later point of time.
config map store data in etcd database in k8s cluster
What is secret ?
if we have sensible data, then it is stored in secret, the secret file it stores the data in encrypted form.
note: if we have nonsesible data then it can store in config map, if it is sensible then store in secret.
the secret file has RBAC(Roll base access control) so that only few people can access that file.


